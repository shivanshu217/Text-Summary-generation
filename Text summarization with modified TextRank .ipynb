{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.TFIDF import *\n",
    "stop = stopwords.words(\"english\")\n",
    "stop = stop + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "    for sentence in article:\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distance(a, b):\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    numerator = 0\n",
    "    denoma = 0\n",
    "    denomb = 0\n",
    "    for i in range(len(a)):\n",
    "        numerator += a[i]*b[i]\n",
    "        denoma += abs(a[i])**2\n",
    "        denomb += abs(b[i])**2\n",
    "    result = 1 - numerator / (math.sqrt(denoma)*math.sqrt(denomb))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(idx1, idx2,sent,values,stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    sent1=sent[idx1]\n",
    "    sent2=sent[idx2]\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += values[idx1][w]\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += values[idx2][w]\n",
    " \n",
    "    return 1 - cos_distance(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(clean_text,values, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    #print(clean_text)\n",
    "    similarity_matrix = np.zeros((len(clean_text), len(clean_text)))\n",
    "    for idx1 in range(len(clean_text)):\n",
    "        for idx2 in range(len(clean_text)):\n",
    "            if idx1 == idx2:\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(idx1, idx2,clean_text,values,stop_words)\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(graph):\n",
    "    n=graph.shape[0]\n",
    "    A = np.zeros((n,1))\n",
    "    A.fill(1/n)\n",
    "    for _ in range(1,100):\n",
    "        A=np.matmul(graph,A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_text(text):\n",
    "    arr = sent_tokenize(text)\n",
    "    new_arr=[]\n",
    "    total_words=[]\n",
    "    for w in arr:\n",
    "        words = word_tokenize(w)\n",
    "        clean=[]\n",
    "        for x in words:\n",
    "            if x.lower() not in stop:\n",
    "                clean.append(x.lower())\n",
    "                total_words.append(x.lower())\n",
    "        new_arr.append(clean)\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(file_name):\n",
    "    f = open(\"summarize.txt\", \"r\")\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = f.read()\n",
    "    sentences=sent_tokenize(text)\n",
    "    clean_text = get_text(text)\n",
    "    \n",
    "    values=get_TF_IDF(file_name)\n",
    "    top_n=3\n",
    "    sentence_similarity_martix = build_similarity_matrix(clean_text,values, stop_words)\n",
    "    scores = pagerank(sentence_similarity_martix)\n",
    "    ranked_sentence=[]\n",
    "    for i in range(len(sentences)):\n",
    "        ranked_sentence.append((scores[i],sentences[i]))\n",
    "    Output = sorted(ranked_sentence, key = lambda x: float(x[0]),reverse=True) \n",
    "    summarize_text=\"\";\n",
    "    for i in range(top_n):\n",
    "        summarize_text+=\" \"+Output[i][1]\n",
    "    print(summarize_text)\n",
    "    return summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [46] Besides school cricket, he also played club cricket, initially representing John Bright Cricket Club in Bombay's premier club cricket tournament, the Kanga League,[43] and later went on to play for the Cricket Club of India. [49] A couple of months later, former Indian batsman Sunil Gavaskar gave him a pair of his own ultra light pads and consoled him to not get disheartened for not getting the Bombay Cricket Association's \"Best junior cricket award\" (He was 14 years that time). [48] On 20 January 1987, he also turned out as substitute for Imran Khan's side in an exhibition game at Brabourne Stadium in Bombay, to mark the golden jubilee of Cricket Club of India.\n"
     ]
    }
   ],
   "source": [
    "answer = summary(\"summarize.txt\")\n",
    "f = open(\"answer.txt\", \"w\")\n",
    "f.write(answer)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
